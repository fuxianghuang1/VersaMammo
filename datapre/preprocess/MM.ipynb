{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancer -> Train: 100%|██████████| 175/175 [00:08<00:00, 20.11it/s]\n",
      "Cancer -> Eval: 100%|██████████| 25/25 [00:02<00:00, 11.69it/s]\n",
      "Cancer -> Test: 100%|██████████| 50/50 [00:02<00:00, 17.71it/s]\n",
      "Non-Cancer -> Train: 100%|██████████| 868/868 [00:45<00:00, 19.05it/s]\n",
      "Non-Cancer -> Eval: 100%|██████████| 124/124 [00:05<00:00, 21.31it/s]\n",
      "Non-Cancer -> Test: 100%|██████████| 248/248 [00:14<00:00, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1022 samples\n",
      "Eval set: 146 samples\n",
      "Test set: 322 samples\n",
      "Processing complete. Results saved to: /Volumes/Newsmy/MM/Breast Cancer Dataset/MM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# 路径配置\n",
    "original_path = \"/Volumes/Newsmy/MM/Breast Cancer Dataset/Original Dataset\"\n",
    "new_dataset_path = \"../classification_data/MM\"\n",
    "split_csv_path = \"../classification_data/classification_split.csv\"\n",
    "\n",
    "def np_CountUpContinuingOnes(b_arr):\n",
    "    \"\"\"计算连续1的区间长度\"\"\"\n",
    "    left = np.arange(len(b_arr))\n",
    "    left[b_arr > 0] = 0\n",
    "    left = np.maximum.accumulate(left)\n",
    "\n",
    "    rev_arr = b_arr[::-1]\n",
    "    right = np.arange(len(rev_arr))\n",
    "    right[rev_arr > 0] = 0\n",
    "    right = np.maximum.accumulate(right)\n",
    "    right = len(rev_arr) - 1 - right[::-1]\n",
    "\n",
    "    return right - left - 1\n",
    "\n",
    "def ExtractBreast(img_array):\n",
    "    \"\"\"乳腺区域提取（输入为numpy数组）\"\"\"\n",
    "    img_copy = img_array.copy()\n",
    "    img_array = np.where(img_array <= 40, 0, img_array)\n",
    "    height, _ = img_array.shape\n",
    "\n",
    "    # 水平方向裁剪\n",
    "    y_a = height // 2 + int(height * 0.4)\n",
    "    y_b = height // 2 - int(height * 0.4)\n",
    "    b_arr = img_array[y_b:y_a].std(axis=0) != 0\n",
    "    continuing_ones = np_CountUpContinuingOnes(b_arr)\n",
    "    col_ind = np.where(continuing_ones == continuing_ones.max())[0]\n",
    "    img_array = img_array[:, col_ind]\n",
    "\n",
    "    # 垂直方向裁剪\n",
    "    _, width = img_array.shape\n",
    "    x_a = width // 2 + int(width * 0.4)\n",
    "    x_b = width // 2 - int(width * 0.4)\n",
    "    b_arr = img_array[:, x_b:x_a].std(axis=1) != 0\n",
    "    continuing_ones = np_CountUpContinuingOnes(b_arr)\n",
    "    row_ind = np.where(continuing_ones == continuing_ones.max())[0]\n",
    "\n",
    "    return img_copy[row_ind][:, col_ind]\n",
    "\n",
    "def process_image(img_path):\n",
    "    \"\"\"处理单个图像文件\"\"\"\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    if img_array.size == 0:\n",
    "        raise ValueError(\"Empty image array\")\n",
    "        \n",
    "    processed_array = ExtractBreast(img_array)\n",
    "    return Image.fromarray(processed_array)\n",
    "\n",
    "def process_dataset():\n",
    "    # 读取数据划分CSV文件\n",
    "    split_df = pd.read_csv(split_csv_path)\n",
    "    split_df = split_df[split_df['dataset'] == 'MM']\n",
    "    \n",
    "    global_idx = 1\n",
    "    \n",
    "    for class_name in [\"Cancer\", \"Non-Cancer\"]:\n",
    "        pathology_label = \"Malignant\" if class_name == \"Cancer\" else \"Benign\"\n",
    "        src_dir = os.path.join(original_path, class_name)\n",
    "        \n",
    "        # 获取并过滤有效图像文件\n",
    "        files = [f for f in os.listdir(src_dir) \n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        for filename in tqdm(files, desc=f\"Processing {class_name}\"):\n",
    "            img_path = os.path.join(src_dir, filename)\n",
    "            if img_path.split('/')[-1].startswith('IMG'):\n",
    "                processed_img = process_image(img_path)\n",
    "                \n",
    "                if processed_img is not None:\n",
    "                    # 创建样本名称\n",
    "                    sample_name = f\"{class_name}_img{global_idx}\"\n",
    "                    \n",
    "                    # 查找对应的data_split\n",
    "                    split_info = split_df[split_df['data_name'] == sample_name]\n",
    "                    if split_info.empty:\n",
    "                        print(f\"No split info found for {sample_name}\")\n",
    "                        continue\n",
    "                    \n",
    "                    data_split = split_info['data_split'].values[0]\n",
    "                    \n",
    "                    # 创建样本目录\n",
    "                    sample_path = os.path.join(new_dataset_path, data_split, sample_name)\n",
    "                    os.makedirs(sample_path, exist_ok=True)\n",
    "                    \n",
    "                    # 保存处理后的图像\n",
    "                    processed_img.save(os.path.join(sample_path, \"img.jpg\"))\n",
    "                    \n",
    "                    # 保存元数据\n",
    "                    info_dict = {\n",
    "                        \"Pathology\": pathology_label\n",
    "                    }\n",
    "                    np.save(os.path.join(sample_path, \"info_dict.npy\"), info_dict)\n",
    "                    \n",
    "                    global_idx += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 清空并重建输出目录\n",
    "    if os.path.exists(new_dataset_path):\n",
    "        import shutil\n",
    "        shutil.rmtree(new_dataset_path)\n",
    "    os.makedirs(new_dataset_path)\n",
    "    \n",
    "    # 处理数据集\n",
    "    process_dataset()\n",
    "    \n",
    "    # 统计结果\n",
    "    for split in [\"Train\", \"Eval\", \"Test\"]:\n",
    "        split_path = os.path.join(new_dataset_path, split)\n",
    "        if os.path.exists(split_path):\n",
    "            count = len(os.listdir(split_path))\n",
    "            print(f\"{split} set: {count} samples\")\n",
    "        else:\n",
    "            print(f\"{split} set: 0 samples (directory not found)\")\n",
    "    \n",
    "    print(f\"Processing complete. Results saved to: {new_dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
